{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from xgboost import XGBClassifier\n",
        "import pickle"
      ],
      "metadata": {
        "id": "ymQdzAihkMEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kp57gqxndnRZ",
        "outputId": "d9f9a1e5-38b9-42f2-e7ea-0028a9793eaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "MOUNT_PATH='/content/drive'\n",
        "drive.mount(MOUNT_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WORKING_DIR=f\"{MOUNT_PATH}/MyDrive/FYP_Research_Work/dataset/CustomYogaPosesDataset\""
      ],
      "metadata": {
        "id": "AhCog4eGkIU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(f\"{WORKING_DIR}/keypoint_dataset_new.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "nAgoP59qkYsx",
        "outputId": "d9753639-4681-42b8-d838-008cb738dca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       k1_x      k1_y      k1_p      k2_x      k2_y      k2_p      k3_x  \\\n",
              "0  0.248363  0.988875  0.749154  0.222718  0.962208  0.680954  0.221534   \n",
              "1  0.319011  0.980275  0.744329  0.308862  0.951305  0.517245  0.309322   \n",
              "2  0.286038  0.972985  0.829567  0.281545  0.941433  0.726869  0.280697   \n",
              "3  0.507017  0.983977  0.774683  0.487512  0.955939  0.804198  0.488540   \n",
              "4  0.224236  0.030090  0.782850  0.194544  0.057158  0.870040  0.193511   \n",
              "\n",
              "       k3_y      k3_p      k4_x  ...     k15_x     k15_y     k15_p     k16_x  \\\n",
              "0  0.961254  0.729572  0.265502  ...  0.692126  0.067509  0.877089  0.270551   \n",
              "1  0.951718  0.581457  0.376711  ...  0.646815  0.032957  0.935496  0.340087   \n",
              "2  0.944313  0.764036  0.356777  ...  0.715659  0.025231  0.883431  0.376844   \n",
              "3  0.956600  0.666367  0.519918  ...  0.554976  0.099207  0.852644  0.291220   \n",
              "4  0.052705  0.880403  0.260465  ...  0.660984  0.853596  0.524160  0.353623   \n",
              "\n",
              "      k16_y     k16_p     k17_x     k17_y     k17_p  Class  \n",
              "0  0.233796  0.394278  0.275390  0.167830  0.307971    Bow  \n",
              "1  0.272476  0.605018  0.328719  0.255500  0.478043    Bow  \n",
              "2  0.286950  0.711141  0.363921  0.284849  0.335781    Bow  \n",
              "3  0.350245  0.422425  0.256430  0.385976  0.579248    Bow  \n",
              "4  0.823096  0.464320  0.350177  0.805742  0.345975    Bow  \n",
              "\n",
              "[5 rows x 52 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e68af8f1-2f51-4fbb-915b-ee3ab1f5673c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>k1_x</th>\n",
              "      <th>k1_y</th>\n",
              "      <th>k1_p</th>\n",
              "      <th>k2_x</th>\n",
              "      <th>k2_y</th>\n",
              "      <th>k2_p</th>\n",
              "      <th>k3_x</th>\n",
              "      <th>k3_y</th>\n",
              "      <th>k3_p</th>\n",
              "      <th>k4_x</th>\n",
              "      <th>...</th>\n",
              "      <th>k15_x</th>\n",
              "      <th>k15_y</th>\n",
              "      <th>k15_p</th>\n",
              "      <th>k16_x</th>\n",
              "      <th>k16_y</th>\n",
              "      <th>k16_p</th>\n",
              "      <th>k17_x</th>\n",
              "      <th>k17_y</th>\n",
              "      <th>k17_p</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.248363</td>\n",
              "      <td>0.988875</td>\n",
              "      <td>0.749154</td>\n",
              "      <td>0.222718</td>\n",
              "      <td>0.962208</td>\n",
              "      <td>0.680954</td>\n",
              "      <td>0.221534</td>\n",
              "      <td>0.961254</td>\n",
              "      <td>0.729572</td>\n",
              "      <td>0.265502</td>\n",
              "      <td>...</td>\n",
              "      <td>0.692126</td>\n",
              "      <td>0.067509</td>\n",
              "      <td>0.877089</td>\n",
              "      <td>0.270551</td>\n",
              "      <td>0.233796</td>\n",
              "      <td>0.394278</td>\n",
              "      <td>0.275390</td>\n",
              "      <td>0.167830</td>\n",
              "      <td>0.307971</td>\n",
              "      <td>Bow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.319011</td>\n",
              "      <td>0.980275</td>\n",
              "      <td>0.744329</td>\n",
              "      <td>0.308862</td>\n",
              "      <td>0.951305</td>\n",
              "      <td>0.517245</td>\n",
              "      <td>0.309322</td>\n",
              "      <td>0.951718</td>\n",
              "      <td>0.581457</td>\n",
              "      <td>0.376711</td>\n",
              "      <td>...</td>\n",
              "      <td>0.646815</td>\n",
              "      <td>0.032957</td>\n",
              "      <td>0.935496</td>\n",
              "      <td>0.340087</td>\n",
              "      <td>0.272476</td>\n",
              "      <td>0.605018</td>\n",
              "      <td>0.328719</td>\n",
              "      <td>0.255500</td>\n",
              "      <td>0.478043</td>\n",
              "      <td>Bow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.286038</td>\n",
              "      <td>0.972985</td>\n",
              "      <td>0.829567</td>\n",
              "      <td>0.281545</td>\n",
              "      <td>0.941433</td>\n",
              "      <td>0.726869</td>\n",
              "      <td>0.280697</td>\n",
              "      <td>0.944313</td>\n",
              "      <td>0.764036</td>\n",
              "      <td>0.356777</td>\n",
              "      <td>...</td>\n",
              "      <td>0.715659</td>\n",
              "      <td>0.025231</td>\n",
              "      <td>0.883431</td>\n",
              "      <td>0.376844</td>\n",
              "      <td>0.286950</td>\n",
              "      <td>0.711141</td>\n",
              "      <td>0.363921</td>\n",
              "      <td>0.284849</td>\n",
              "      <td>0.335781</td>\n",
              "      <td>Bow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.507017</td>\n",
              "      <td>0.983977</td>\n",
              "      <td>0.774683</td>\n",
              "      <td>0.487512</td>\n",
              "      <td>0.955939</td>\n",
              "      <td>0.804198</td>\n",
              "      <td>0.488540</td>\n",
              "      <td>0.956600</td>\n",
              "      <td>0.666367</td>\n",
              "      <td>0.519918</td>\n",
              "      <td>...</td>\n",
              "      <td>0.554976</td>\n",
              "      <td>0.099207</td>\n",
              "      <td>0.852644</td>\n",
              "      <td>0.291220</td>\n",
              "      <td>0.350245</td>\n",
              "      <td>0.422425</td>\n",
              "      <td>0.256430</td>\n",
              "      <td>0.385976</td>\n",
              "      <td>0.579248</td>\n",
              "      <td>Bow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.224236</td>\n",
              "      <td>0.030090</td>\n",
              "      <td>0.782850</td>\n",
              "      <td>0.194544</td>\n",
              "      <td>0.057158</td>\n",
              "      <td>0.870040</td>\n",
              "      <td>0.193511</td>\n",
              "      <td>0.052705</td>\n",
              "      <td>0.880403</td>\n",
              "      <td>0.260465</td>\n",
              "      <td>...</td>\n",
              "      <td>0.660984</td>\n",
              "      <td>0.853596</td>\n",
              "      <td>0.524160</td>\n",
              "      <td>0.353623</td>\n",
              "      <td>0.823096</td>\n",
              "      <td>0.464320</td>\n",
              "      <td>0.350177</td>\n",
              "      <td>0.805742</td>\n",
              "      <td>0.345975</td>\n",
              "      <td>Bow</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 52 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e68af8f1-2f51-4fbb-915b-ee3ab1f5673c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e68af8f1-2f51-4fbb-915b-ee3ab1f5673c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e68af8f1-2f51-4fbb-915b-ee3ab1f5673c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-93202459-67a6-43a7-9393-2739bd4f1555\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-93202459-67a6-43a7-9393-2739bd4f1555')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-93202459-67a6-43a7-9393-2739bd4f1555 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Use value_counts to get the count of each unique value in the 'class' column\n",
        "class_counts = data['Class'].value_counts()\n",
        "\n",
        "# Print the number of different classes and the count of datapoints for each class\n",
        "print(\"Number of different classes:\", len(class_counts))\n",
        "print(\"\\nCount of datapoints for each class:\")\n",
        "print(class_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lna3qvmGklc4",
        "outputId": "779ced2e-8a64-4a6a-d6b6-bcfbe833f1f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of different classes: 21\n",
            "\n",
            "Count of datapoints for each class:\n",
            "Cow                                  57\n",
            "Wheel                                56\n",
            "Camel                                56\n",
            "Warrior Two                          56\n",
            "Upward-Facing Dog                    55\n",
            "Crow                                 54\n",
            "Side Plank                           54\n",
            "Forward Bend with Shoulder Opener    53\n",
            "Bridge                               53\n",
            "Extended Side Angle                  52\n",
            "Tree                                 50\n",
            "Warrior One                          50\n",
            "Shoulder Stand                       49\n",
            "Warrior Three                        47\n",
            "Bow                                  47\n",
            "Plank                                47\n",
            "Half-Moon                            46\n",
            "Extended Hand to Toe                 46\n",
            "Sphinx                               45\n",
            "Cat                                  43\n",
            "Low Lunge                            43\n",
            "Name: Class, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(columns=['Class'])\n",
        "Y = data['Class']"
      ],
      "metadata": {
        "id": "v9pYvp8olAqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "AgGyub1JkyUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "8cEW-sEG7RKM",
        "outputId": "0055bf54-9f97-4ce9-a28e-774952e02aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          k1_x      k1_y      k1_p      k2_x      k2_y      k2_p      k3_x  \\\n",
              "331   0.096584  0.621855  0.833973  0.080050  0.640502  0.724018  0.076904   \n",
              "44    0.491671  0.126696  0.136636  0.459802  0.123073  0.241004  0.459493   \n",
              "307   0.729738  0.304276  0.682489  0.712803  0.286931  0.816269  0.713763   \n",
              "323   0.100845  0.353371  0.901726  0.079737  0.371075  0.669280  0.077063   \n",
              "1009  0.445297  0.922846  0.535923  0.465667  0.906631  0.631968  0.467438   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "330   0.141507  0.647163  0.611045  0.119610  0.665046  0.850726  0.121197   \n",
              "466   0.547243  0.069563  0.757728  0.530127  0.050601  0.761084  0.565494   \n",
              "121   0.089754  0.106167  0.608884  0.129277  0.107875  0.549608  0.128557   \n",
              "1044  0.480423  0.038391  0.747687  0.501549  0.056376  0.645997  0.500300   \n",
              "860   0.309066  0.517998  0.523844  0.296905  0.502002  0.555641  0.297412   \n",
              "\n",
              "          k3_y      k3_p      k4_x  ...     k14_p     k15_x     k15_y  \\\n",
              "331   0.636845  0.737998  0.093701  ...  0.918348  0.336473  0.433809   \n",
              "44    0.093364  0.227062  0.466824  ...  0.034181  0.594769  0.536735   \n",
              "307   0.286510  0.787554  0.654395  ...  0.821927  0.667456  0.489033   \n",
              "323   0.333716  0.816456  0.083788  ...  0.942254  0.716414  0.382389   \n",
              "1009  0.906542  0.569442  0.466882  ...  0.867792  0.399318  0.218970   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "330   0.628039  0.592151  0.126523  ...  0.881923  0.373475  0.375650   \n",
              "466   0.063561  0.690223  0.490004  ...  0.818854  0.648036  0.442071   \n",
              "121   0.106349  0.657165  0.173459  ...  0.296557  0.910898  0.737836   \n",
              "1044  0.053673  0.715097  0.493879  ...  0.703535  0.541798  0.656502   \n",
              "860   0.496177  0.747975  0.324486  ...  0.954343  0.783718  0.347518   \n",
              "\n",
              "         k15_p     k16_x     k16_y     k16_p     k17_x     k17_y     k17_p  \n",
              "331   0.894641  0.932283  0.648071  0.906676  0.253058  0.222607  0.782247  \n",
              "44    0.078319  0.562474  0.609822  0.050201  0.538600  0.551654  0.072901  \n",
              "307   0.657485  0.584305  0.700092  0.768742  0.583252  0.694109  0.728086  \n",
              "323   0.929647  0.149895  0.811074  0.643243  0.927168  0.421633  0.953900  \n",
              "1009  0.926082  0.700477  0.268634  0.825691  0.668455  0.263736  0.779650  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "330   0.599598  0.942979  0.576519  0.872164  0.257645  0.197467  0.655249  \n",
              "466   0.892190  0.224754  0.911937  0.625169  0.877192  0.435545  0.817403  \n",
              "121   0.615029  0.784760  0.373591  0.462166  0.903696  0.328683  0.620171  \n",
              "1044  0.699382  0.738796  0.851115  0.760085  0.713137  0.818105  0.467676  \n",
              "860   0.851622  0.908526  0.722237  0.938191  0.925297  0.204957  0.926052  \n",
              "\n",
              "[847 rows x 51 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d413c2b4-acbb-462b-a49a-9eb7f005aa95\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>k1_x</th>\n",
              "      <th>k1_y</th>\n",
              "      <th>k1_p</th>\n",
              "      <th>k2_x</th>\n",
              "      <th>k2_y</th>\n",
              "      <th>k2_p</th>\n",
              "      <th>k3_x</th>\n",
              "      <th>k3_y</th>\n",
              "      <th>k3_p</th>\n",
              "      <th>k4_x</th>\n",
              "      <th>...</th>\n",
              "      <th>k14_p</th>\n",
              "      <th>k15_x</th>\n",
              "      <th>k15_y</th>\n",
              "      <th>k15_p</th>\n",
              "      <th>k16_x</th>\n",
              "      <th>k16_y</th>\n",
              "      <th>k16_p</th>\n",
              "      <th>k17_x</th>\n",
              "      <th>k17_y</th>\n",
              "      <th>k17_p</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>331</th>\n",
              "      <td>0.096584</td>\n",
              "      <td>0.621855</td>\n",
              "      <td>0.833973</td>\n",
              "      <td>0.080050</td>\n",
              "      <td>0.640502</td>\n",
              "      <td>0.724018</td>\n",
              "      <td>0.076904</td>\n",
              "      <td>0.636845</td>\n",
              "      <td>0.737998</td>\n",
              "      <td>0.093701</td>\n",
              "      <td>...</td>\n",
              "      <td>0.918348</td>\n",
              "      <td>0.336473</td>\n",
              "      <td>0.433809</td>\n",
              "      <td>0.894641</td>\n",
              "      <td>0.932283</td>\n",
              "      <td>0.648071</td>\n",
              "      <td>0.906676</td>\n",
              "      <td>0.253058</td>\n",
              "      <td>0.222607</td>\n",
              "      <td>0.782247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.491671</td>\n",
              "      <td>0.126696</td>\n",
              "      <td>0.136636</td>\n",
              "      <td>0.459802</td>\n",
              "      <td>0.123073</td>\n",
              "      <td>0.241004</td>\n",
              "      <td>0.459493</td>\n",
              "      <td>0.093364</td>\n",
              "      <td>0.227062</td>\n",
              "      <td>0.466824</td>\n",
              "      <td>...</td>\n",
              "      <td>0.034181</td>\n",
              "      <td>0.594769</td>\n",
              "      <td>0.536735</td>\n",
              "      <td>0.078319</td>\n",
              "      <td>0.562474</td>\n",
              "      <td>0.609822</td>\n",
              "      <td>0.050201</td>\n",
              "      <td>0.538600</td>\n",
              "      <td>0.551654</td>\n",
              "      <td>0.072901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307</th>\n",
              "      <td>0.729738</td>\n",
              "      <td>0.304276</td>\n",
              "      <td>0.682489</td>\n",
              "      <td>0.712803</td>\n",
              "      <td>0.286931</td>\n",
              "      <td>0.816269</td>\n",
              "      <td>0.713763</td>\n",
              "      <td>0.286510</td>\n",
              "      <td>0.787554</td>\n",
              "      <td>0.654395</td>\n",
              "      <td>...</td>\n",
              "      <td>0.821927</td>\n",
              "      <td>0.667456</td>\n",
              "      <td>0.489033</td>\n",
              "      <td>0.657485</td>\n",
              "      <td>0.584305</td>\n",
              "      <td>0.700092</td>\n",
              "      <td>0.768742</td>\n",
              "      <td>0.583252</td>\n",
              "      <td>0.694109</td>\n",
              "      <td>0.728086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>0.100845</td>\n",
              "      <td>0.353371</td>\n",
              "      <td>0.901726</td>\n",
              "      <td>0.079737</td>\n",
              "      <td>0.371075</td>\n",
              "      <td>0.669280</td>\n",
              "      <td>0.077063</td>\n",
              "      <td>0.333716</td>\n",
              "      <td>0.816456</td>\n",
              "      <td>0.083788</td>\n",
              "      <td>...</td>\n",
              "      <td>0.942254</td>\n",
              "      <td>0.716414</td>\n",
              "      <td>0.382389</td>\n",
              "      <td>0.929647</td>\n",
              "      <td>0.149895</td>\n",
              "      <td>0.811074</td>\n",
              "      <td>0.643243</td>\n",
              "      <td>0.927168</td>\n",
              "      <td>0.421633</td>\n",
              "      <td>0.953900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1009</th>\n",
              "      <td>0.445297</td>\n",
              "      <td>0.922846</td>\n",
              "      <td>0.535923</td>\n",
              "      <td>0.465667</td>\n",
              "      <td>0.906631</td>\n",
              "      <td>0.631968</td>\n",
              "      <td>0.467438</td>\n",
              "      <td>0.906542</td>\n",
              "      <td>0.569442</td>\n",
              "      <td>0.466882</td>\n",
              "      <td>...</td>\n",
              "      <td>0.867792</td>\n",
              "      <td>0.399318</td>\n",
              "      <td>0.218970</td>\n",
              "      <td>0.926082</td>\n",
              "      <td>0.700477</td>\n",
              "      <td>0.268634</td>\n",
              "      <td>0.825691</td>\n",
              "      <td>0.668455</td>\n",
              "      <td>0.263736</td>\n",
              "      <td>0.779650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>330</th>\n",
              "      <td>0.141507</td>\n",
              "      <td>0.647163</td>\n",
              "      <td>0.611045</td>\n",
              "      <td>0.119610</td>\n",
              "      <td>0.665046</td>\n",
              "      <td>0.850726</td>\n",
              "      <td>0.121197</td>\n",
              "      <td>0.628039</td>\n",
              "      <td>0.592151</td>\n",
              "      <td>0.126523</td>\n",
              "      <td>...</td>\n",
              "      <td>0.881923</td>\n",
              "      <td>0.373475</td>\n",
              "      <td>0.375650</td>\n",
              "      <td>0.599598</td>\n",
              "      <td>0.942979</td>\n",
              "      <td>0.576519</td>\n",
              "      <td>0.872164</td>\n",
              "      <td>0.257645</td>\n",
              "      <td>0.197467</td>\n",
              "      <td>0.655249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>466</th>\n",
              "      <td>0.547243</td>\n",
              "      <td>0.069563</td>\n",
              "      <td>0.757728</td>\n",
              "      <td>0.530127</td>\n",
              "      <td>0.050601</td>\n",
              "      <td>0.761084</td>\n",
              "      <td>0.565494</td>\n",
              "      <td>0.063561</td>\n",
              "      <td>0.690223</td>\n",
              "      <td>0.490004</td>\n",
              "      <td>...</td>\n",
              "      <td>0.818854</td>\n",
              "      <td>0.648036</td>\n",
              "      <td>0.442071</td>\n",
              "      <td>0.892190</td>\n",
              "      <td>0.224754</td>\n",
              "      <td>0.911937</td>\n",
              "      <td>0.625169</td>\n",
              "      <td>0.877192</td>\n",
              "      <td>0.435545</td>\n",
              "      <td>0.817403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>0.089754</td>\n",
              "      <td>0.106167</td>\n",
              "      <td>0.608884</td>\n",
              "      <td>0.129277</td>\n",
              "      <td>0.107875</td>\n",
              "      <td>0.549608</td>\n",
              "      <td>0.128557</td>\n",
              "      <td>0.106349</td>\n",
              "      <td>0.657165</td>\n",
              "      <td>0.173459</td>\n",
              "      <td>...</td>\n",
              "      <td>0.296557</td>\n",
              "      <td>0.910898</td>\n",
              "      <td>0.737836</td>\n",
              "      <td>0.615029</td>\n",
              "      <td>0.784760</td>\n",
              "      <td>0.373591</td>\n",
              "      <td>0.462166</td>\n",
              "      <td>0.903696</td>\n",
              "      <td>0.328683</td>\n",
              "      <td>0.620171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1044</th>\n",
              "      <td>0.480423</td>\n",
              "      <td>0.038391</td>\n",
              "      <td>0.747687</td>\n",
              "      <td>0.501549</td>\n",
              "      <td>0.056376</td>\n",
              "      <td>0.645997</td>\n",
              "      <td>0.500300</td>\n",
              "      <td>0.053673</td>\n",
              "      <td>0.715097</td>\n",
              "      <td>0.493879</td>\n",
              "      <td>...</td>\n",
              "      <td>0.703535</td>\n",
              "      <td>0.541798</td>\n",
              "      <td>0.656502</td>\n",
              "      <td>0.699382</td>\n",
              "      <td>0.738796</td>\n",
              "      <td>0.851115</td>\n",
              "      <td>0.760085</td>\n",
              "      <td>0.713137</td>\n",
              "      <td>0.818105</td>\n",
              "      <td>0.467676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>0.309066</td>\n",
              "      <td>0.517998</td>\n",
              "      <td>0.523844</td>\n",
              "      <td>0.296905</td>\n",
              "      <td>0.502002</td>\n",
              "      <td>0.555641</td>\n",
              "      <td>0.297412</td>\n",
              "      <td>0.496177</td>\n",
              "      <td>0.747975</td>\n",
              "      <td>0.324486</td>\n",
              "      <td>...</td>\n",
              "      <td>0.954343</td>\n",
              "      <td>0.783718</td>\n",
              "      <td>0.347518</td>\n",
              "      <td>0.851622</td>\n",
              "      <td>0.908526</td>\n",
              "      <td>0.722237</td>\n",
              "      <td>0.938191</td>\n",
              "      <td>0.925297</td>\n",
              "      <td>0.204957</td>\n",
              "      <td>0.926052</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>847 rows × 51 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d413c2b4-acbb-462b-a49a-9eb7f005aa95')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d413c2b4-acbb-462b-a49a-9eb7f005aa95 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d413c2b4-acbb-462b-a49a-9eb7f005aa95');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-638b4065-894d-464f-95ea-8f8f137934cb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-638b4065-894d-464f-95ea-8f8f137934cb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-638b4065-894d-464f-95ea-8f8f137934cb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuNoAq1H9QgG",
        "outputId": "a08e5c9c-261b-4b75-a288-c26bf84664e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "k1_x     0.096584\n",
              "k1_y     0.621855\n",
              "k1_p     0.833973\n",
              "k2_x     0.080050\n",
              "k2_y     0.640502\n",
              "k2_p     0.724018\n",
              "k3_x     0.076904\n",
              "k3_y     0.636845\n",
              "k3_p     0.737998\n",
              "k4_x     0.093701\n",
              "k4_y     0.696285\n",
              "k4_p     0.834298\n",
              "k5_x     0.088340\n",
              "k5_y     0.688931\n",
              "k5_p     0.827541\n",
              "k6_x     0.204414\n",
              "k6_y     0.750159\n",
              "k6_p     0.916794\n",
              "k7_x     0.178667\n",
              "k7_y     0.617596\n",
              "k7_p     0.620026\n",
              "k8_x     0.345318\n",
              "k8_y     0.809331\n",
              "k8_p     0.942531\n",
              "k9_x     0.185166\n",
              "k9_y     0.455999\n",
              "k9_p     0.772330\n",
              "k10_x    0.424565\n",
              "k10_y    0.691492\n",
              "k10_p    0.826326\n",
              "k11_x    0.176570\n",
              "k11_y    0.311771\n",
              "k11_p    0.899527\n",
              "k12_x    0.466827\n",
              "k12_y    0.643310\n",
              "k12_p    0.852040\n",
              "k13_x    0.428260\n",
              "k13_y    0.598103\n",
              "k13_p    0.880925\n",
              "k14_x    0.705478\n",
              "k14_y    0.633976\n",
              "k14_p    0.918348\n",
              "k15_x    0.336473\n",
              "k15_y    0.433809\n",
              "k15_p    0.894641\n",
              "k16_x    0.932283\n",
              "k16_y    0.648071\n",
              "k16_p    0.906676\n",
              "k17_x    0.253058\n",
              "k17_y    0.222607\n",
              "k17_p    0.782247\n",
              "Name: 331, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "GwVR0oSmlO2d",
        "outputId": "1306c3c4-6067-46d8-ff2f-cddf5e54c70d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         k1_x      k1_y      k1_p      k2_x      k2_y      k2_p      k3_x  \\\n",
              "576  0.522771  0.911949  0.609212  0.503894  0.921883  0.613233  0.501511   \n",
              "312  0.186113  0.516202  0.632114  0.171749  0.532401  0.773987  0.170401   \n",
              "70   0.514455  0.153359  0.677294  0.533465  0.127323  0.603322  0.540741   \n",
              "682  0.420179  0.143992  0.679242  0.414045  0.130108  0.952725  0.439726   \n",
              "896  0.271319  0.381479  0.849420  0.284950  0.365035  0.854822  0.290155   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "55   0.543216  0.833646  0.605873  0.560792  0.860739  0.671531  0.557092   \n",
              "120  0.034036  0.173029  0.560722  0.067948  0.169069  0.615779  0.065832   \n",
              "533  0.295526  0.442879  0.817816  0.292307  0.472638  0.800647  0.291403   \n",
              "25   0.304258  0.015514  0.807599  0.270565  0.031674  0.742549  0.268325   \n",
              "72   0.516932  0.195194  0.622272  0.530033  0.175309  0.510965  0.531272   \n",
              "\n",
              "         k3_y      k3_p      k4_x  ...     k14_p     k15_x     k15_y  \\\n",
              "576  0.920926  0.499995  0.459458  ...  0.708835  0.495830  0.311953   \n",
              "312  0.519519  0.796785  0.183869  ...  0.921476  0.315532  0.284798   \n",
              "70   0.120422  0.822288  0.602968  ...  0.497668  0.283159  0.978568   \n",
              "682  0.112617  0.898974  0.436778  ...  0.774842  0.777850  0.705085   \n",
              "896  0.359745  0.822169  0.342994  ...  0.898557  0.779433  0.323461   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "55   0.861066  0.806034  0.637639  ...  0.692421  0.297262  0.187714   \n",
              "120  0.172260  0.563783  0.131554  ...  0.433718  0.960655  0.746873   \n",
              "533  0.466538  0.581968  0.336509  ...  0.881417  0.920633  0.616483   \n",
              "25   0.032307  0.752679  0.306534  ...  0.725609  0.628634  0.918885   \n",
              "72   0.174736  0.612127  0.579858  ...  0.784863  0.374178  0.709720   \n",
              "\n",
              "        k15_p     k16_x     k16_y     k16_p     k17_x     k17_y     k17_p  \n",
              "576  0.677345  0.532438  0.133789  0.627446  0.540199  0.127359  0.746140  \n",
              "312  0.912241  0.927976  0.472846  0.888596  0.170204  0.160819  0.877073  \n",
              "70   0.874081  0.570826  0.894936  0.792130  0.674627  0.968889  0.778858  \n",
              "682  0.781920  0.844127  0.942585  0.765748  0.872486  0.927339  0.892132  \n",
              "896  0.898706  0.879473  0.838911  0.898402  0.898741  0.143048  0.791884  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "55   0.845416  0.629021  0.179208  0.597652  0.619226  0.172897  0.608641  \n",
              "120  0.726027  0.937339  0.313198  0.531511  0.935885  0.287364  0.470828  \n",
              "533  0.684513  0.918872  0.174790  0.938086  0.914088  0.913603  0.655840  \n",
              "25   0.666534  0.375000  0.925423  0.114138  0.307977  0.925913  0.139540  \n",
              "72   0.836579  0.586579  0.687433  0.675891  0.592395  0.704679  0.834647  \n",
              "\n",
              "[212 rows x 51 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6ca1b00-91d2-4cb3-824e-67f1ba8959b9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>k1_x</th>\n",
              "      <th>k1_y</th>\n",
              "      <th>k1_p</th>\n",
              "      <th>k2_x</th>\n",
              "      <th>k2_y</th>\n",
              "      <th>k2_p</th>\n",
              "      <th>k3_x</th>\n",
              "      <th>k3_y</th>\n",
              "      <th>k3_p</th>\n",
              "      <th>k4_x</th>\n",
              "      <th>...</th>\n",
              "      <th>k14_p</th>\n",
              "      <th>k15_x</th>\n",
              "      <th>k15_y</th>\n",
              "      <th>k15_p</th>\n",
              "      <th>k16_x</th>\n",
              "      <th>k16_y</th>\n",
              "      <th>k16_p</th>\n",
              "      <th>k17_x</th>\n",
              "      <th>k17_y</th>\n",
              "      <th>k17_p</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>576</th>\n",
              "      <td>0.522771</td>\n",
              "      <td>0.911949</td>\n",
              "      <td>0.609212</td>\n",
              "      <td>0.503894</td>\n",
              "      <td>0.921883</td>\n",
              "      <td>0.613233</td>\n",
              "      <td>0.501511</td>\n",
              "      <td>0.920926</td>\n",
              "      <td>0.499995</td>\n",
              "      <td>0.459458</td>\n",
              "      <td>...</td>\n",
              "      <td>0.708835</td>\n",
              "      <td>0.495830</td>\n",
              "      <td>0.311953</td>\n",
              "      <td>0.677345</td>\n",
              "      <td>0.532438</td>\n",
              "      <td>0.133789</td>\n",
              "      <td>0.627446</td>\n",
              "      <td>0.540199</td>\n",
              "      <td>0.127359</td>\n",
              "      <td>0.746140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312</th>\n",
              "      <td>0.186113</td>\n",
              "      <td>0.516202</td>\n",
              "      <td>0.632114</td>\n",
              "      <td>0.171749</td>\n",
              "      <td>0.532401</td>\n",
              "      <td>0.773987</td>\n",
              "      <td>0.170401</td>\n",
              "      <td>0.519519</td>\n",
              "      <td>0.796785</td>\n",
              "      <td>0.183869</td>\n",
              "      <td>...</td>\n",
              "      <td>0.921476</td>\n",
              "      <td>0.315532</td>\n",
              "      <td>0.284798</td>\n",
              "      <td>0.912241</td>\n",
              "      <td>0.927976</td>\n",
              "      <td>0.472846</td>\n",
              "      <td>0.888596</td>\n",
              "      <td>0.170204</td>\n",
              "      <td>0.160819</td>\n",
              "      <td>0.877073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>0.514455</td>\n",
              "      <td>0.153359</td>\n",
              "      <td>0.677294</td>\n",
              "      <td>0.533465</td>\n",
              "      <td>0.127323</td>\n",
              "      <td>0.603322</td>\n",
              "      <td>0.540741</td>\n",
              "      <td>0.120422</td>\n",
              "      <td>0.822288</td>\n",
              "      <td>0.602968</td>\n",
              "      <td>...</td>\n",
              "      <td>0.497668</td>\n",
              "      <td>0.283159</td>\n",
              "      <td>0.978568</td>\n",
              "      <td>0.874081</td>\n",
              "      <td>0.570826</td>\n",
              "      <td>0.894936</td>\n",
              "      <td>0.792130</td>\n",
              "      <td>0.674627</td>\n",
              "      <td>0.968889</td>\n",
              "      <td>0.778858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>682</th>\n",
              "      <td>0.420179</td>\n",
              "      <td>0.143992</td>\n",
              "      <td>0.679242</td>\n",
              "      <td>0.414045</td>\n",
              "      <td>0.130108</td>\n",
              "      <td>0.952725</td>\n",
              "      <td>0.439726</td>\n",
              "      <td>0.112617</td>\n",
              "      <td>0.898974</td>\n",
              "      <td>0.436778</td>\n",
              "      <td>...</td>\n",
              "      <td>0.774842</td>\n",
              "      <td>0.777850</td>\n",
              "      <td>0.705085</td>\n",
              "      <td>0.781920</td>\n",
              "      <td>0.844127</td>\n",
              "      <td>0.942585</td>\n",
              "      <td>0.765748</td>\n",
              "      <td>0.872486</td>\n",
              "      <td>0.927339</td>\n",
              "      <td>0.892132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>896</th>\n",
              "      <td>0.271319</td>\n",
              "      <td>0.381479</td>\n",
              "      <td>0.849420</td>\n",
              "      <td>0.284950</td>\n",
              "      <td>0.365035</td>\n",
              "      <td>0.854822</td>\n",
              "      <td>0.290155</td>\n",
              "      <td>0.359745</td>\n",
              "      <td>0.822169</td>\n",
              "      <td>0.342994</td>\n",
              "      <td>...</td>\n",
              "      <td>0.898557</td>\n",
              "      <td>0.779433</td>\n",
              "      <td>0.323461</td>\n",
              "      <td>0.898706</td>\n",
              "      <td>0.879473</td>\n",
              "      <td>0.838911</td>\n",
              "      <td>0.898402</td>\n",
              "      <td>0.898741</td>\n",
              "      <td>0.143048</td>\n",
              "      <td>0.791884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>0.543216</td>\n",
              "      <td>0.833646</td>\n",
              "      <td>0.605873</td>\n",
              "      <td>0.560792</td>\n",
              "      <td>0.860739</td>\n",
              "      <td>0.671531</td>\n",
              "      <td>0.557092</td>\n",
              "      <td>0.861066</td>\n",
              "      <td>0.806034</td>\n",
              "      <td>0.637639</td>\n",
              "      <td>...</td>\n",
              "      <td>0.692421</td>\n",
              "      <td>0.297262</td>\n",
              "      <td>0.187714</td>\n",
              "      <td>0.845416</td>\n",
              "      <td>0.629021</td>\n",
              "      <td>0.179208</td>\n",
              "      <td>0.597652</td>\n",
              "      <td>0.619226</td>\n",
              "      <td>0.172897</td>\n",
              "      <td>0.608641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>0.034036</td>\n",
              "      <td>0.173029</td>\n",
              "      <td>0.560722</td>\n",
              "      <td>0.067948</td>\n",
              "      <td>0.169069</td>\n",
              "      <td>0.615779</td>\n",
              "      <td>0.065832</td>\n",
              "      <td>0.172260</td>\n",
              "      <td>0.563783</td>\n",
              "      <td>0.131554</td>\n",
              "      <td>...</td>\n",
              "      <td>0.433718</td>\n",
              "      <td>0.960655</td>\n",
              "      <td>0.746873</td>\n",
              "      <td>0.726027</td>\n",
              "      <td>0.937339</td>\n",
              "      <td>0.313198</td>\n",
              "      <td>0.531511</td>\n",
              "      <td>0.935885</td>\n",
              "      <td>0.287364</td>\n",
              "      <td>0.470828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>533</th>\n",
              "      <td>0.295526</td>\n",
              "      <td>0.442879</td>\n",
              "      <td>0.817816</td>\n",
              "      <td>0.292307</td>\n",
              "      <td>0.472638</td>\n",
              "      <td>0.800647</td>\n",
              "      <td>0.291403</td>\n",
              "      <td>0.466538</td>\n",
              "      <td>0.581968</td>\n",
              "      <td>0.336509</td>\n",
              "      <td>...</td>\n",
              "      <td>0.881417</td>\n",
              "      <td>0.920633</td>\n",
              "      <td>0.616483</td>\n",
              "      <td>0.684513</td>\n",
              "      <td>0.918872</td>\n",
              "      <td>0.174790</td>\n",
              "      <td>0.938086</td>\n",
              "      <td>0.914088</td>\n",
              "      <td>0.913603</td>\n",
              "      <td>0.655840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.304258</td>\n",
              "      <td>0.015514</td>\n",
              "      <td>0.807599</td>\n",
              "      <td>0.270565</td>\n",
              "      <td>0.031674</td>\n",
              "      <td>0.742549</td>\n",
              "      <td>0.268325</td>\n",
              "      <td>0.032307</td>\n",
              "      <td>0.752679</td>\n",
              "      <td>0.306534</td>\n",
              "      <td>...</td>\n",
              "      <td>0.725609</td>\n",
              "      <td>0.628634</td>\n",
              "      <td>0.918885</td>\n",
              "      <td>0.666534</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.925423</td>\n",
              "      <td>0.114138</td>\n",
              "      <td>0.307977</td>\n",
              "      <td>0.925913</td>\n",
              "      <td>0.139540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>0.516932</td>\n",
              "      <td>0.195194</td>\n",
              "      <td>0.622272</td>\n",
              "      <td>0.530033</td>\n",
              "      <td>0.175309</td>\n",
              "      <td>0.510965</td>\n",
              "      <td>0.531272</td>\n",
              "      <td>0.174736</td>\n",
              "      <td>0.612127</td>\n",
              "      <td>0.579858</td>\n",
              "      <td>...</td>\n",
              "      <td>0.784863</td>\n",
              "      <td>0.374178</td>\n",
              "      <td>0.709720</td>\n",
              "      <td>0.836579</td>\n",
              "      <td>0.586579</td>\n",
              "      <td>0.687433</td>\n",
              "      <td>0.675891</td>\n",
              "      <td>0.592395</td>\n",
              "      <td>0.704679</td>\n",
              "      <td>0.834647</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>212 rows × 51 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6ca1b00-91d2-4cb3-824e-67f1ba8959b9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c6ca1b00-91d2-4cb3-824e-67f1ba8959b9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c6ca1b00-91d2-4cb3-824e-67f1ba8959b9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cac31324-ddd4-4a44-879f-c8fc36ee801e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cac31324-ddd4-4a44-879f-c8fc36ee801e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cac31324-ddd4-4a44-879f-c8fc36ee801e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform labels in y_train and y_valid\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_valid_encoded = label_encoder.transform(y_valid)"
      ],
      "metadata": {
        "id": "_VCvOPKeju1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the mapping of labels to encoded values\n",
        "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "\n",
        "print(\"Label Mapping:\", label_mapping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuO1HPsyhxej",
        "outputId": "486d470d-7e4b-4f0b-dbd4-5e7b0bf174a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Mapping: {'Bow': 0, 'Bridge': 1, 'Camel': 2, 'Cat': 3, 'Cow': 4, 'Crow': 5, 'Extended Hand to Toe': 6, 'Extended Side Angle': 7, 'Forward Bend with Shoulder Opener': 8, 'Half-Moon': 9, 'Low Lunge': 10, 'Plank': 11, 'Shoulder Stand': 12, 'Side Plank': 13, 'Sphinx': 14, 'Tree': 15, 'Upward-Facing Dog': 16, 'Warrior One': 17, 'Warrior Three': 18, 'Warrior Two': 19, 'Wheel': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "rlcQCx8rnp9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 21"
      ],
      "metadata": {
        "id": "OGmJ-q6Rlr_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "XNwvtsEjnjrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q3RhNK4tZFV",
        "outputId": "ad60c648-3822-4b01-cbde-9f000e2498b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(847, 51)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and train the classifier\n",
        "classifier_model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "R47_VzbJoLzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.summary()  # Print the model summary to verify the changes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1zlQKZLshQt",
        "outputId": "bd417860-b6b6-49d1-e7b7-627d0349f72b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               6656      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 25)                1625      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16537 (64.60 KB)\n",
            "Trainable params: 16537 (64.60 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=30\n",
        "history = classifier_model.fit(X_train, y_train_encoded, validation_data=(X_valid, y_valid_encoded), epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PJVUYF9sgqX",
        "outputId": "6ba290c3-cbb4-4a69-b51c-2833b6510f97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 1s 11ms/step - loss: 2.9822 - accuracy: 0.0945 - val_loss: 2.8931 - val_accuracy: 0.1132\n",
            "Epoch 2/30\n",
            " 1/27 [>.............................] - ETA: 0s - loss: 2.8624 - accuracy: 0.2188"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/27 [==============================] - 0s 3ms/step - loss: 2.8107 - accuracy: 0.1995 - val_loss: 2.7329 - val_accuracy: 0.2123\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2.6082 - accuracy: 0.2845 - val_loss: 2.5079 - val_accuracy: 0.3396\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2.3624 - accuracy: 0.3896 - val_loss: 2.2705 - val_accuracy: 0.3396\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2.1015 - accuracy: 0.4073 - val_loss: 2.0047 - val_accuracy: 0.4906\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.8418 - accuracy: 0.5313 - val_loss: 1.7824 - val_accuracy: 0.5425\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.6274 - accuracy: 0.5797 - val_loss: 1.6022 - val_accuracy: 0.5566\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.4475 - accuracy: 0.6399 - val_loss: 1.4958 - val_accuracy: 0.6085\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.3167 - accuracy: 0.6659 - val_loss: 1.3601 - val_accuracy: 0.6415\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.1890 - accuracy: 0.7096 - val_loss: 1.2347 - val_accuracy: 0.6887\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0835 - accuracy: 0.7296 - val_loss: 1.1906 - val_accuracy: 0.7028\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1.0071 - accuracy: 0.7591 - val_loss: 1.0846 - val_accuracy: 0.7500\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.9254 - accuracy: 0.7780 - val_loss: 1.0434 - val_accuracy: 0.7736\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.8525 - accuracy: 0.7851 - val_loss: 1.0025 - val_accuracy: 0.7877\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7949 - accuracy: 0.8146 - val_loss: 0.9542 - val_accuracy: 0.7925\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7297 - accuracy: 0.8359 - val_loss: 0.9353 - val_accuracy: 0.8160\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7019 - accuracy: 0.8253 - val_loss: 0.8922 - val_accuracy: 0.8113\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6765 - accuracy: 0.8170 - val_loss: 0.8668 - val_accuracy: 0.8349\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6158 - accuracy: 0.8571 - val_loss: 0.8564 - val_accuracy: 0.7877\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5809 - accuracy: 0.8619 - val_loss: 0.8418 - val_accuracy: 0.8208\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5584 - accuracy: 0.8642 - val_loss: 0.8327 - val_accuracy: 0.8113\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.8831 - val_loss: 0.7837 - val_accuracy: 0.8302\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.8737 - val_loss: 0.7801 - val_accuracy: 0.8302\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.8784 - val_loss: 0.7422 - val_accuracy: 0.8726\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.8642 - val_loss: 0.7922 - val_accuracy: 0.8160\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.8914 - val_loss: 0.7166 - val_accuracy: 0.8679\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.8843 - val_loss: 0.7386 - val_accuracy: 0.8302\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8890 - val_loss: 0.7136 - val_accuracy: 0.8443\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8867 - val_loss: 0.6994 - val_accuracy: 0.8774\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.3762 - accuracy: 0.9032 - val_loss: 0.6910 - val_accuracy: 0.8774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation set\n",
        "loss, accuracy = classifier_model.evaluate(X_valid, y_valid_encoded)\n",
        "print(f'Validation Loss: {loss}')\n",
        "print(f'Validation Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "km9W8XtlkNn5",
        "outputId": "a83dd056-c553-49a0-8c14-d69091f6e0d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 1ms/step - loss: 0.4409 - accuracy: 0.8613\n",
            "Validation Loss: 0.4409447908401489\n",
            "Validation Accuracy: 0.8613445162773132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the model to TFLite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(classifier_model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model\n",
        "with open(f'{MOUNT_PATH}/MyDrive/FYP_Research_Work/dataset/CustomYogaPoses/keypoints_to_pose_classifier_v1.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n"
      ],
      "metadata": {
        "id": "k4StazS1k1EO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "xLHz2EvXodGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "id": "pYE7-wMnmd4c",
        "outputId": "e8ca3199-c191-44bc-f800-be6b2828eeb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning - method 1"
      ],
      "metadata": {
        "id": "Redpoe9ztWX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB8-f5VWrHYD",
        "outputId": "ed400c05-cb18-4b40-c973-429e899d428a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.12.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.10/dist-packages (from scikeras) (23.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.2.0)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from scikeras.wrappers import KerasClassifier"
      ],
      "metadata": {
        "id": "URIJ3156lZt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function that creates a Keras model\n",
        "def create_model(num_layers=2, neurons=64):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(neurons, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    for _ in range(num_layers - 1):\n",
        "        model.add(Dense(neurons, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "LS37P-2roulK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a KerasClassifier based on the above function\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)"
      ],
      "metadata": {
        "id": "r1lXDtVbo8p5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameters to tune\n",
        "param_grid = {\n",
        "    'num_layers': [1, 2, 3],  # Number of hidden layers\n",
        "}"
      ],
      "metadata": {
        "id": "1OFEC8wUo_ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a GridSearchCV object\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=1)\n"
      ],
      "metadata": {
        "id": "IJpMnN4zpErU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Perform the grid search\n",
        "grid_result = grid.fit(X_train, y_train_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "X2WszbhmpGQa",
        "outputId": "83e55d6a-d3e8-4509-8d74-d52b35b0f4c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid parameter num_layers for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(num_layers=1)`\nCheck the list of available parameters with `estimator.get_params().keys()`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-5ba285a1055f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Perform the grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0mcloned_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m   1163\u001b[0m                     \u001b[0;31m# Give a SciKeras specific user message to aid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m                     \u001b[0;31m# in moving from the Keras wrappers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m   1166\u001b[0m                         \u001b[0;34mf\"Invalid parameter {param} for estimator {self.__name__}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m                         \u001b[0;34m\"\\nThis issue can likely be resolved by setting this parameter\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid parameter num_layers for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(num_layers=1)`\nCheck the list of available parameters with `estimator.get_params().keys()`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print the best parameters and the corresponding accuracy\n",
        "print(\"Best parameters found: \", grid_result.best_params_)\n",
        "print(\"Best accuracy found: \", grid_result.best_score_)\n"
      ],
      "metadata": {
        "id": "q6Bi4pyVknev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning - method 2"
      ],
      "metadata": {
        "id": "BdOdJYxmthJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "iCWq8wNetgVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkJOc-SpttQa",
        "outputId": "65d25bbf-83fc-44ab-9ece-2ed41194ad85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/128.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/128.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m92.2/128.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt"
      ],
      "metadata": {
        "id": "TaPx8uistvty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_builder(hp):\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  # Tune the number of units in the first Dense layer\n",
        "  # Choose an optimal value between 32-512\n",
        "  hp_units_l1 = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "  model.add(keras.layers.Dense(units=hp_units_l1, activation='relu'))\n",
        "\n",
        "  # Tune the number of units in the second Dense layer\n",
        "  # Choose an optimal value between 32-512\n",
        "  hp_units_l2 = hp.Int('units', min_value=64, max_value=256, step=32)\n",
        "  model.add(keras.layers.Dense(units=hp_units_l2, activation='relu'))\n",
        "  model.add(keras.layers.Dense(units=25, activation='softmax'))\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "KbZXA3CYt9bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsLVvcfau6kt",
        "outputId": "32977fb2-4c92-4837-b451-6efe01f05686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from my_dir/intro_to_kt/tuner0.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
      ],
      "metadata": {
        "id": "MQqFmLfYu_rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train, y_train_encoded, validation_data=(X_valid, y_valid_encoded), epochs=50, callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal number of units in the second densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwxxuNIfvHtO",
        "outputId": "c7a0ab0a-434a-4ded-9d3e-f71d3dce823c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
            "layer is 480 and the optimal number of units in the second densely-connected\n",
            "layer is 480 and the optimal learning rate for the optimizer\n",
            "is 0.001.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(X_train, y_train_encoded, validation_data=(X_valid, y_valid_encoded), epochs=50)\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MvDUCqLviTg",
        "outputId": "17cbd065-4d34-4277-b5e3-1df517eb8397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30/30 [==============================] - 1s 9ms/step - loss: 3.2052 - accuracy: 0.0652 - val_loss: 3.1409 - val_accuracy: 0.0798\n",
            "Epoch 2/50\n",
            "27/30 [==========================>...] - ETA: 0s - loss: 3.0988 - accuracy: 0.1215"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r30/30 [==============================] - 0s 4ms/step - loss: 3.0903 - accuracy: 0.1272 - val_loss: 3.0198 - val_accuracy: 0.1471\n",
            "Epoch 3/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 2.9309 - accuracy: 0.1714 - val_loss: 2.8574 - val_accuracy: 0.1681\n",
            "Epoch 4/50\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 2.7357 - accuracy: 0.2324 - val_loss: 2.6486 - val_accuracy: 0.2437\n",
            "Epoch 5/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 2.5144 - accuracy: 0.3333 - val_loss: 2.4579 - val_accuracy: 0.3193\n",
            "Epoch 6/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 2.3135 - accuracy: 0.3491 - val_loss: 2.2704 - val_accuracy: 0.4076\n",
            "Epoch 7/50\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 2.1338 - accuracy: 0.4479 - val_loss: 2.1079 - val_accuracy: 0.4202\n",
            "Epoch 8/50\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.9724 - accuracy: 0.4974 - val_loss: 1.9465 - val_accuracy: 0.5084\n",
            "Epoch 9/50\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.8243 - accuracy: 0.5237 - val_loss: 1.8163 - val_accuracy: 0.5378\n",
            "Epoch 10/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.7014 - accuracy: 0.5741 - val_loss: 1.6850 - val_accuracy: 0.5630\n",
            "Epoch 11/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.5867 - accuracy: 0.5836 - val_loss: 1.5846 - val_accuracy: 0.5126\n",
            "Epoch 12/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.4868 - accuracy: 0.6067 - val_loss: 1.4710 - val_accuracy: 0.6092\n",
            "Epoch 13/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.3829 - accuracy: 0.6456 - val_loss: 1.3863 - val_accuracy: 0.6261\n",
            "Epoch 14/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.3117 - accuracy: 0.6614 - val_loss: 1.3284 - val_accuracy: 0.6303\n",
            "Epoch 15/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.2182 - accuracy: 0.6940 - val_loss: 1.2252 - val_accuracy: 0.6555\n",
            "Epoch 16/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.1620 - accuracy: 0.6993 - val_loss: 1.1856 - val_accuracy: 0.6345\n",
            "Epoch 17/50\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.0963 - accuracy: 0.7192 - val_loss: 1.1056 - val_accuracy: 0.6765\n",
            "Epoch 18/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.0462 - accuracy: 0.7287 - val_loss: 1.0583 - val_accuracy: 0.7185\n",
            "Epoch 19/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.9875 - accuracy: 0.7424 - val_loss: 1.0105 - val_accuracy: 0.7101\n",
            "Epoch 20/50\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9428 - accuracy: 0.7508 - val_loss: 0.9525 - val_accuracy: 0.7311\n",
            "Epoch 21/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.9000 - accuracy: 0.7687 - val_loss: 0.9039 - val_accuracy: 0.7437\n",
            "Epoch 22/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.8482 - accuracy: 0.7897 - val_loss: 0.8719 - val_accuracy: 0.7689\n",
            "Epoch 23/50\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8167 - accuracy: 0.8055 - val_loss: 0.8403 - val_accuracy: 0.7899\n",
            "Epoch 24/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.7955 - accuracy: 0.8076 - val_loss: 0.8162 - val_accuracy: 0.8151\n",
            "Epoch 25/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.7648 - accuracy: 0.8086 - val_loss: 0.7874 - val_accuracy: 0.7857\n",
            "Epoch 26/50\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7404 - accuracy: 0.8065 - val_loss: 0.7950 - val_accuracy: 0.7689\n",
            "Epoch 27/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.7222 - accuracy: 0.8275 - val_loss: 0.7818 - val_accuracy: 0.7605\n",
            "Epoch 28/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.8254 - val_loss: 0.7406 - val_accuracy: 0.7815\n",
            "Epoch 29/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.6732 - accuracy: 0.8318 - val_loss: 0.7120 - val_accuracy: 0.7731\n",
            "Epoch 30/50\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6413 - accuracy: 0.8318 - val_loss: 0.6791 - val_accuracy: 0.7941\n",
            "Epoch 31/50\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6257 - accuracy: 0.8402 - val_loss: 0.6512 - val_accuracy: 0.8319\n",
            "Epoch 32/50\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6109 - accuracy: 0.8339 - val_loss: 0.6573 - val_accuracy: 0.8319\n",
            "Epoch 33/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.8496 - val_loss: 0.6152 - val_accuracy: 0.8445\n",
            "Epoch 34/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.8538 - val_loss: 0.6316 - val_accuracy: 0.8067\n",
            "Epoch 35/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5644 - accuracy: 0.8423 - val_loss: 0.5877 - val_accuracy: 0.8361\n",
            "Epoch 36/50\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.8633 - val_loss: 0.6012 - val_accuracy: 0.8109\n",
            "Epoch 37/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.8433 - val_loss: 0.5791 - val_accuracy: 0.8109\n",
            "Epoch 38/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.8549 - val_loss: 0.5658 - val_accuracy: 0.8403\n",
            "Epoch 39/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.8633 - val_loss: 0.5742 - val_accuracy: 0.8151\n",
            "Epoch 40/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.8612 - val_loss: 0.5507 - val_accuracy: 0.8361\n",
            "Epoch 41/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.8559 - val_loss: 0.5549 - val_accuracy: 0.8277\n",
            "Epoch 42/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.8623 - val_loss: 0.5283 - val_accuracy: 0.8235\n",
            "Epoch 43/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.8717 - val_loss: 0.5357 - val_accuracy: 0.8361\n",
            "Epoch 44/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.8686 - val_loss: 0.5357 - val_accuracy: 0.8361\n",
            "Epoch 45/50\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.8780 - val_loss: 0.5177 - val_accuracy: 0.8403\n",
            "Epoch 46/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.8696 - val_loss: 0.5298 - val_accuracy: 0.8445\n",
            "Epoch 47/50\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.8665 - val_loss: 0.5046 - val_accuracy: 0.8487\n",
            "Epoch 48/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.8749 - val_loss: 0.4931 - val_accuracy: 0.8445\n",
            "Epoch 49/50\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.8759 - val_loss: 0.4933 - val_accuracy: 0.8445\n",
            "Epoch 50/50\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.8707 - val_loss: 0.5143 - val_accuracy: 0.8319\n",
            "Best epoch: 47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(X_train, y_train_encoded, validation_data=(X_valid, y_valid_encoded), epochs=best_epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHYFfdHIxMdf",
        "outputId": "2001f4da-2611-4d4f-d7d2-96966159432d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30/30 [==============================] - 1s 9ms/step - loss: 3.1964 - accuracy: 0.0589 - val_loss: 3.1437 - val_accuracy: 0.0966\n",
            "Epoch 2/47\n",
            "21/30 [====================>.........] - ETA: 0s - loss: 3.0943 - accuracy: 0.1220"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r30/30 [==============================] - 0s 4ms/step - loss: 3.0728 - accuracy: 0.1178 - val_loss: 3.0228 - val_accuracy: 0.1345\n",
            "Epoch 3/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 2.9231 - accuracy: 0.2019 - val_loss: 2.8466 - val_accuracy: 0.2437\n",
            "Epoch 4/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 2.7157 - accuracy: 0.2871 - val_loss: 2.6209 - val_accuracy: 0.2647\n",
            "Epoch 5/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 2.4826 - accuracy: 0.3291 - val_loss: 2.3888 - val_accuracy: 0.4496\n",
            "Epoch 6/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 2.2482 - accuracy: 0.4217 - val_loss: 2.1807 - val_accuracy: 0.4790\n",
            "Epoch 7/47\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 2.0370 - accuracy: 0.4606 - val_loss: 1.9748 - val_accuracy: 0.5420\n",
            "Epoch 8/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.8551 - accuracy: 0.5121 - val_loss: 1.8440 - val_accuracy: 0.5126\n",
            "Epoch 9/47\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.6956 - accuracy: 0.5542 - val_loss: 1.6816 - val_accuracy: 0.5126\n",
            "Epoch 10/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.5612 - accuracy: 0.5868 - val_loss: 1.5331 - val_accuracy: 0.6008\n",
            "Epoch 11/47\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.4375 - accuracy: 0.6172 - val_loss: 1.4317 - val_accuracy: 0.5924\n",
            "Epoch 12/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.3431 - accuracy: 0.6446 - val_loss: 1.3732 - val_accuracy: 0.5924\n",
            "Epoch 13/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.2694 - accuracy: 0.6467 - val_loss: 1.2458 - val_accuracy: 0.6513\n",
            "Epoch 14/47\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.1935 - accuracy: 0.6803 - val_loss: 1.2058 - val_accuracy: 0.6092\n",
            "Epoch 15/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.1176 - accuracy: 0.7056 - val_loss: 1.1260 - val_accuracy: 0.6765\n",
            "Epoch 16/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.0670 - accuracy: 0.7098 - val_loss: 1.1060 - val_accuracy: 0.6387\n",
            "Epoch 17/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.0076 - accuracy: 0.7403 - val_loss: 1.0285 - val_accuracy: 0.6933\n",
            "Epoch 18/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9742 - accuracy: 0.7487 - val_loss: 0.9821 - val_accuracy: 0.6933\n",
            "Epoch 19/47\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.9347 - accuracy: 0.7518 - val_loss: 0.9416 - val_accuracy: 0.6975\n",
            "Epoch 20/47\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.9026 - accuracy: 0.7539 - val_loss: 0.8995 - val_accuracy: 0.7395\n",
            "Epoch 21/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8623 - accuracy: 0.7666 - val_loss: 0.8801 - val_accuracy: 0.7227\n",
            "Epoch 22/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8265 - accuracy: 0.7729 - val_loss: 0.8275 - val_accuracy: 0.7815\n",
            "Epoch 23/47\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.7975 - accuracy: 0.7855 - val_loss: 0.8083 - val_accuracy: 0.7773\n",
            "Epoch 24/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7620 - accuracy: 0.7992 - val_loss: 0.7749 - val_accuracy: 0.8025\n",
            "Epoch 25/47\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.7430 - accuracy: 0.8076 - val_loss: 0.7553 - val_accuracy: 0.7983\n",
            "Epoch 26/47\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.7229 - accuracy: 0.8097 - val_loss: 0.7374 - val_accuracy: 0.7899\n",
            "Epoch 27/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6980 - accuracy: 0.8149 - val_loss: 0.7175 - val_accuracy: 0.8067\n",
            "Epoch 28/47\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.8275 - val_loss: 0.6847 - val_accuracy: 0.8193\n",
            "Epoch 29/47\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.8128 - val_loss: 0.6783 - val_accuracy: 0.8403\n",
            "Epoch 30/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6530 - accuracy: 0.8339 - val_loss: 0.6463 - val_accuracy: 0.8151\n",
            "Epoch 31/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6220 - accuracy: 0.8318 - val_loss: 0.6473 - val_accuracy: 0.8235\n",
            "Epoch 32/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6145 - accuracy: 0.8170 - val_loss: 0.6186 - val_accuracy: 0.8235\n",
            "Epoch 33/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.5975 - accuracy: 0.8381 - val_loss: 0.6070 - val_accuracy: 0.8403\n",
            "Epoch 34/47\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5871 - accuracy: 0.8444 - val_loss: 0.6079 - val_accuracy: 0.8193\n",
            "Epoch 35/47\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.8391 - val_loss: 0.5877 - val_accuracy: 0.8361\n",
            "Epoch 36/47\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.8517 - val_loss: 0.5618 - val_accuracy: 0.8319\n",
            "Epoch 37/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.5512 - accuracy: 0.8454 - val_loss: 0.5677 - val_accuracy: 0.8361\n",
            "Epoch 38/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.8570 - val_loss: 0.5737 - val_accuracy: 0.8361\n",
            "Epoch 39/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.8559 - val_loss: 0.5256 - val_accuracy: 0.8445\n",
            "Epoch 40/47\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.8601 - val_loss: 0.5124 - val_accuracy: 0.8487\n",
            "Epoch 41/47\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.8623 - val_loss: 0.5002 - val_accuracy: 0.8529\n",
            "Epoch 42/47\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.8444 - val_loss: 0.5211 - val_accuracy: 0.8403\n",
            "Epoch 43/47\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.8665 - val_loss: 0.5000 - val_accuracy: 0.8613\n",
            "Epoch 44/47\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.8591 - val_loss: 0.4953 - val_accuracy: 0.8487\n",
            "Epoch 45/47\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.8717 - val_loss: 0.4813 - val_accuracy: 0.8529\n",
            "Epoch 46/47\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.8833 - val_loss: 0.4754 - val_accuracy: 0.8487\n",
            "Epoch 47/47\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.8707 - val_loss: 0.4962 - val_accuracy: 0.8403\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d4af44bbdc0>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = hypermodel.evaluate(X_valid, y_valid_encoded)\n",
        "print(\"[test loss, test accuracy]:\", eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "9JY7FxCRxeP0",
        "outputId": "a9ab8556-a55b-45d1-ffa1-420c816b2d47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'hypermodel' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-be90cbc1195f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[test loss, test accuracy]:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'hypermodel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAML Approach"
      ],
      "metadata": {
        "id": "PZJBI027l6mI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers"
      ],
      "metadata": {
        "id": "0QSOTmIqmJrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#num_classes = 25"
      ],
      "metadata": {
        "id": "HIdkZYv3m6Zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define MAML model\n",
        "def get_maml_model():\n",
        "    # Create a meta-learner model\n",
        "    meta_model = models.Sequential([\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the meta-model\n",
        "    meta_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return meta_model"
      ],
      "metadata": {
        "id": "TUas34rLl_GB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define MAML training procedure\n",
        "def maml_train_step(model, support_set, query_set):\n",
        "    # Training step for one meta-batch\n",
        "    support_input, support_labels = support_set\n",
        "    query_input, query_labels = query_set\n",
        "\n",
        "    # Fine-tune the model on the support set\n",
        "    model.fit(support_input, support_labels, epochs=5, verbose=0)\n",
        "\n",
        "    # Evaluate on the query set\n",
        "    loss, accuracy = model.evaluate(query_input, query_labels, verbose=0)\n",
        "\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "rWLUcdo0mfN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "XeJmwJtDpV-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to one-hot encoding\n",
        "num_classes = len(np.unique(y_train_encoded))\n",
        "labels_train_onehot = to_categorical(y_train_encoded, num_classes)\n",
        "labels_test_onehot = to_categorical(y_valid_encoded, num_classes)"
      ],
      "metadata": {
        "id": "Q3M9BjMinPtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print information about the dataset\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "print(f\"Number of training samples: {len(X_train)}\")\n",
        "print(f\"Number of testing samples: {len(X_valid)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TBBpjs4piqn",
        "outputId": "68723818-0705-4b7c-8f51-61aea8cf0c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 25\n",
            "Number of training samples: 951\n",
            "Number of testing samples: 238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into meta-training and meta-testing sets\n",
        "meta_train_data = (X_train, labels_train_onehot)\n",
        "meta_test_data = (X_valid, labels_test_onehot)"
      ],
      "metadata": {
        "id": "2ClHzGeoqoXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a MAML model\n",
        "maml_model = get_maml_model()"
      ],
      "metadata": {
        "id": "dhMaoLFuqzc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of meta-batches and meta-iterations\n",
        "num_meta_batches = 100\n",
        "num_meta_iterations = 5"
      ],
      "metadata": {
        "id": "dDpCWKU9q83g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " import random\n",
        "\n",
        "def sample_meta_batch(meta_data, batch_size=5):\n",
        "    # meta_data is a tuple containing images and labels for the meta-training set\n",
        "    X, labels = meta_data\n",
        "\n",
        "    # Convert labels to a pandas Series\n",
        "    labels_series = pd.Series(labels)\n",
        "\n",
        "    # Randomly sample a meta-batch\n",
        "    sampled_indices = random.sample(range(len(X)), batch_size)\n",
        "    sampled_X = X.iloc[sampled_indices]\n",
        "    sampled_labels = labels.iloc[sampled_indices]\n",
        "\n",
        "    return sampled_X, sampled_labels"
      ],
      "metadata": {
        "id": "gim1wJwWrBdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Meta-training loop\n",
        "for meta_iteration in range(num_meta_iterations):\n",
        "    for meta_batch in range(num_meta_batches):\n",
        "        # Sample a random meta-batch from the meta-training set\n",
        "        support_set = sample_meta_batch(meta_train_data)\n",
        "        query_set = sample_meta_batch(meta_train_data)\n",
        "\n",
        "        # Perform a meta-training step\n",
        "        loss, accuracy = maml_train_step(maml_model, support_set, query_set)\n",
        "\n",
        "        print(f'Meta-Iteration: {meta_iteration + 1}, Meta-Batch: {meta_batch + 1}, Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "JFAVfwpErm8d",
        "outputId": "d7094794-3c1d-454b-fdd8-d73a7812442d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Data must be 1-dimensional",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-0e49cf81fcbc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmeta_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_meta_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m# Sample a random meta-batch from the meta-training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0msupport_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_meta_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mquery_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_meta_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-9aa2b0c3612b>\u001b[0m in \u001b[0;36msample_meta_batch\u001b[0;34m(meta_data, batch_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Convert labels to a pandas Series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mlabels_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Randomly sample a meta-batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    468\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                 \u001b[0mmanager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.data_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m     \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_ndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36m_sanitize_ndim\u001b[0;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data must be 1-dimensional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtensionDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m             \u001b[0;31m# i.e. PandasDtype(\"O\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data must be 1-dimensional"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metric Learning"
      ],
      "metadata": {
        "id": "sz6ySbFaZC_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ],
      "metadata": {
        "id": "0hfcqzKEZKxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input layer for 51 features\n",
        "inputs = layers.Input(shape=(51,))"
      ],
      "metadata": {
        "id": "nM5E6tD0ZNpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hidden layers with Leaky ReLU activation\n",
        "x = layers.Dense(128, activation=\"relu\")(inputs)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "\n",
        "# Embedding layer for metric learning\n",
        "embeddings = layers.Dense(32)(x)  # Adjust embedding dimension as needed\n",
        "\n",
        "# Output layer for classification\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(embeddings)\n",
        "\n",
        "# Define model\n",
        "model = models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Loss function using cross-entropy\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "metadata": {
        "id": "0G-H5DKYZWiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model.compile(loss=loss_fn, optimizer=optimizer, metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "ZU0JhKpfZYpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train_encoded, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyKwyszHZZ2m",
        "outputId": "a16a5747-3de4-462d-bab7-2ee76ce2b4b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30/30 [==============================] - 1s 2ms/step - loss: 3.1495 - accuracy: 0.0852\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 2.9192 - accuracy: 0.2292\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 2.5630 - accuracy: 0.3575\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 2.1347 - accuracy: 0.4395\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.7637 - accuracy: 0.5037\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.4800 - accuracy: 0.6172\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.2705 - accuracy: 0.6467\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 1.0892 - accuracy: 0.7077\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.9546 - accuracy: 0.7455\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.8560 - accuracy: 0.7550\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7917902127d0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model.evaluate(X_valid, y_valid_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GwZnnHlZbin",
        "outputId": "fdec78f3-a27b-4435-c525-979b423fd4fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/8 [==>...........................] - ETA: 2s - loss: 0.9889 - accuracy: 0.6562"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r8/8 [==============================] - 0s 6ms/step - loss: 0.8941 - accuracy: 0.7185\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.894101619720459, 0.7184873819351196]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract embeddings for further analysis\n",
        "pose_embeddings = model.predict(X_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDr8NM7lZHDE",
        "outputId": "f2eced83-dce0-4ade-80ef-73d4e19170df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions from the trained model\n",
        "y_pred = model.predict(X_valid)\n",
        "\n",
        "# Convert predictions to class labels (e.g., using argmax)\n",
        "y_pred_labels = tf.math.argmax(y_pred, axis=1)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "confusion_matrix = tf.math.confusion_matrix(y_valid_encoded, y_pred_labels)\n",
        "\n",
        "# Print or visualize the confusion matrix\n",
        "print(confusion_matrix.numpy())  # Or use libraries like matplotlib for visualization\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpI3P543bMl9",
        "outputId": "78310145-b459-4bb4-dbc0-271d30715825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 3ms/step\n",
            "[[ 2  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0\n",
            "   0]\n",
            " [ 0  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0\n",
            "   0]\n",
            " [ 1  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1\n",
            "   0]\n",
            " [ 0  0  0  0  0  0  0  0  0  5  0  0  0  0  0  1  0  0  0  0  0  0  0  0\n",
            "   0]\n",
            " [ 0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  1  0  0  0  0  0  0  0  1  0  0\n",
            "   0]\n",
            " [ 0  0  0  0  0  0 13  0  1  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0\n",
            "   0]\n",
            " [ 0  0  0  0  0  1  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0]\n",
            " [ 0  0  0  0  0  0  8  0  0  0  2  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0]\n",
            " [ 0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0]\n",
            " [ 0  0  0  0  0  0  2  0  0  0  3  4  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0]\n",
            " [ 1  0  0  0  0  0  0  0  0  0  0  0  1 10  0  0  0  0  0  0  0  0  0  0\n",
            "   0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0\n",
            "   0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  9  0  0  0  0  0  0  0  0\n",
            "   0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 10  0  0  0  0  0  0  0\n",
            "   0]\n",
            " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0\n",
            "   1]\n",
            " [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0\n",
            "   0]\n",
            " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0\n",
            "   8]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0\n",
            "   0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  2  7  0  1\n",
            "   0]\n",
            " [ 0  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  2  0\n",
            "   0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10\n",
            "   0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  1  0  0  0\n",
            "   9]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}